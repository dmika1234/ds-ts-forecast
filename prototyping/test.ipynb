{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Local imports\n",
    "src_dir = os.path.abspath('../')\n",
    "os.chdir(src_dir)\n",
    "sys.path.append(src_dir)\n",
    "from src.config import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import warnings\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_notebook_options(matplotlib_params_dct={}, plt_style='fivethirtyeight'):\n",
    "    # Set matplotlib params\n",
    "    default_matplotlib_params_dct = {'axes.labelsize': 14,\n",
    "                                    'xtick.labelsize': 12,\n",
    "                                    'ytick.labelsize': 12,\n",
    "                                    'text.color': 'k'}\n",
    "    matplotlib_params_dct = default_matplotlib_params_dct | matplotlib_params_dct\n",
    "    for key, value in matplotlib_params_dct.items():\n",
    "        matplotlib.rcParams[key] = value\n",
    "    # Plt style\n",
    "    plt.style.use(plt_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, data_dir=DATA_DIR):\n",
    "        self.data_dir = data_dir\n",
    "        self.data = None\n",
    "        self.loaded_data_dct = {}\n",
    "    \n",
    "    def load_data(self, data_file, *args, **kwargs):\n",
    "        if data_file == 'co2_data':\n",
    "            self.data = sm.datasets.co2.load_pandas().data\n",
    "        else:  \n",
    "            data_path = os.path.join(self.data_dir, data_file)\n",
    "            self.data = pd.read_csv(data_path, *args, **kwargs)\n",
    "        \n",
    "        self.loaded_data_dct[data_file] = self.data\n",
    "\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, data=None):\n",
    "        self.data = data\n",
    "    \n",
    "    def set_dt_index(self, dt_col, data=None, inplace=False):\n",
    "        data = self.data if data is None else data\n",
    "        if data is None:\n",
    "            raise ValueError('No data provided!')\n",
    "        if not inplace:\n",
    "            data = data.copy()\n",
    "        data[dt_col] = pd.to_datetime(data[dt_col])\n",
    "        data = data.set_index(dt_col)\n",
    "        data = data.sort_index()\n",
    "        if inplace:\n",
    "            self.data = data\n",
    "        return data\n",
    "    \n",
    "    def sort_index(self, data=None, inplace=False):\n",
    "        data = self.data if data is None else data\n",
    "        if data is None:\n",
    "            raise ValueError('No data provided!')\n",
    "        if not inplace:\n",
    "            data = data.copy()\n",
    "        data = data.sort_index()\n",
    "        if inplace:\n",
    "            self.data = data\n",
    "        return data\n",
    "    \n",
    "    def rename_dt_index(self, new_name='', data=None, inplace=False):\n",
    "        data = self.data if data is None else data\n",
    "        if data is None:\n",
    "            raise ValueError('No data provided!')\n",
    "        if not inplace:\n",
    "            data = data.copy()\n",
    "        data.index.names = [new_name]\n",
    "        if inplace:\n",
    "            self.data = data\n",
    "        return data\n",
    "\n",
    "    def rename_df_columns(self, col_name_map={}, data=None, inplace=False):\n",
    "        data = self.data if data is None else data\n",
    "        if data is None:\n",
    "            raise ValueError('No data provided!')\n",
    "        if not inplace:\n",
    "            data = data.copy()\n",
    "        data = data.rename(columns=col_name_map)\n",
    "        if inplace:\n",
    "            self.data = data\n",
    "        return data\n",
    "\n",
    "    def drop(self, data=None, inplace=False, *args, **kwargs):\n",
    "        data = self.data if data is None else data\n",
    "        if data is None:\n",
    "            raise ValueError('No data provided!')\n",
    "        if not inplace:\n",
    "            data = data.copy()\n",
    "        data = data.drop(*args, **kwargs)\n",
    "        if inplace:\n",
    "            self.data = data\n",
    "        return data\n",
    "    \n",
    "    def select_columns(self, columns=[], data=None, inplace=False, *args, **kwargs):\n",
    "        data = self.data if data is None else data\n",
    "        if data is None:\n",
    "            raise ValueError('No data provided!')\n",
    "        if not inplace:\n",
    "            data = data.copy()\n",
    "        data = data[columns]\n",
    "        if inplace:\n",
    "            self.data = data\n",
    "        return data\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CO2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataLoader().load_data('co2_data')\n",
    "dp = DataProcessor(df)\n",
    "dp.sort_index(inplace=False)\n",
    "dp.rename_dt_index('dt', inplace=True)\n",
    "dp.rename_df_columns({'co2': 'y'}, inplace=True)\n",
    "co2_df = dp.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'MS' string groups the data in buckets by start of the month\n",
    "co2_df = dp.set_dt_index('dt', data=co2_df.resample('MS').mean().reset_index())\n",
    "# The term bfill means that we use the value before filling in missing values\n",
    "co2_df = co2_df.fillna(co2_df.bfill())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "import itertools\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "split_year_str = str(co2_df.index.year.unique()[int(co2_df.index.year.nunique() * train_size)])\n",
    "split_date_dt = pd.to_datetime(datetime.strptime(split_year_str, '%Y').date())\n",
    "\n",
    "train = co2_df.loc[co2_df.index < split_date_dt]\n",
    "test = co2_df.loc[co2_df.index >= split_date_dt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca118befac6046df86c73c47e89f1508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/324 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "train_metric = 'mse'\n",
    "\n",
    "# Define the parameter grids\n",
    "p_values = range(0, 3)\n",
    "d_values = range(0, 2)\n",
    "q_values = range(0, 3)\n",
    "P_values = range(0, 3)\n",
    "D_values = range(0, 2)\n",
    "Q_values = range(0, 3)\n",
    "s_values = [12]\n",
    "\n",
    "param_grid = list(itertools.product(p_values, d_values, q_values, P_values, D_values, Q_values, s_values))\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "best_metric_value= np.inf\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "# Perform a parameter grid search\n",
    "for params in tqdm(param_grid):\n",
    "    param, param_seasonal = params[:3], params[3:]\n",
    "    cv_metrics = []\n",
    "    # Perfomr cross-validation\n",
    "    for train_idx, val_idx in tscv.split(co2_df):\n",
    "        # Obtain the train and test sets\n",
    "        train = co2_df.iloc[train_idx]\n",
    "        test = co2_df.iloc[val_idx]\n",
    "        # Train the model\n",
    "        try:\n",
    "            sarimax_model = sm.tsa.statespace.SARIMAX(train,\n",
    "                                                    order=param,\n",
    "                                                    seasonal_order=param_seasonal,\n",
    "                                                    enforce_stationarity=False,\n",
    "                                                    enforce_invertibility=False)\n",
    "            sarimax_model_fit = sarimax_model.fit()\n",
    "        except:\n",
    "            continue\n",
    "        # Make predictions\n",
    "        y_pred = sarimax_model_fit.get_prediction(start=test.index.min(), end=test.index.max(), dynamic=False).predicted_mean\n",
    "        y_pred.index.name = 'dt'\n",
    "        y_pred = dp.set_dt_index('dt', data=y_pred.reset_index())\n",
    "        y_pred = dp.rename_df_columns({'predicted_mean': 'y'}, data=y_pred)\n",
    "        # Calculate the metric\n",
    "        if train_metric == 'aic':\n",
    "            train_metric_val = sarimax_model_fit.aic\n",
    "        elif train_metric == 'mse':\n",
    "            train_metric_val = mean_squared_error(test, y_pred)\n",
    "        elif train_metric == 'rmse':\n",
    "            train_metric_val = np.sqrtr(mean_squared_error(test, y_pred))\n",
    "        \n",
    "        cv_metrics.append(train_metric_val)\n",
    "    # Aggregate the metrics\n",
    "    cv_metrics_agg = np.mean(cv_metrics)\n",
    "    # Update the best model\n",
    "    if cv_metrics_agg < best_metric_value:\n",
    "        best_metric_value = cv_metrics_agg\n",
    "        best_params = params\n",
    "        best_model = sarimax_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SarimaxGridSearchCV:\n",
    "\n",
    "    def __init__(self, tscv_splits=2):\n",
    "        self.best_metric_value= np.inf\n",
    "        self._time_series_splitter = TimeSeriesSplit(n_splits=tscv_splits)\n",
    "        self.best_cv_params = None\n",
    "        self.best_cv_model = None\n",
    "        self.model = None\n",
    "    \n",
    "    @property\n",
    "    def time_series_splitter(self):\n",
    "        return self._time_series_splitter\n",
    "    \n",
    "    @time_series_splitter.setter\n",
    "    def time_series_splitter(self, tscv_splits=2):\n",
    "        if tscv_splits >= 2:\n",
    "            self._time_series_splitter = TimeSeriesSplit(n_splits=tscv_splits)\n",
    "        else:\n",
    "            raise ValueError('Number of splits must be at least 2!')\n",
    "\n",
    "    def fit(self, data, param_grid, train_metric='mse', tscv_splits=5):\n",
    "        # if time_series_splitter is none initialize it\n",
    "        if tscv_splits is not None:\n",
    "            self.time_series_splitter = tscv_splits\n",
    "\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "        # Perform a parameter grid search\n",
    "        for params in tqdm(param_grid):\n",
    "            param, param_seasonal = params[:3], params[3:]\n",
    "            cv_metrics = []\n",
    "            # Perfomr cross-validation\n",
    "            for train_idx, val_idx in self.time_series_splitter.split(data):\n",
    "                # Obtain the train and test sets\n",
    "                train = data.iloc[train_idx]\n",
    "                test = data.iloc[val_idx]\n",
    "                # Train the model\n",
    "                try:\n",
    "                    sarimax_model = sm.tsa.statespace.SARIMAX(train,\n",
    "                                                            order=param,\n",
    "                                                            seasonal_order=param_seasonal,\n",
    "                                                            enforce_stationarity=True,\n",
    "                                                            enforce_invertibility=True)\n",
    "                    sarimax_model_fit = sarimax_model.fit()\n",
    "                except:\n",
    "                    continue\n",
    "                # Make predictions\n",
    "                y_pred = sarimax_model_fit.get_prediction(start=test.index.min(), end=test.index.max(), dynamic=False).predicted_mean\n",
    "                y_pred.index.name = 'dt'\n",
    "                y_pred = dp.set_dt_index('dt', data=y_pred.reset_index())\n",
    "                y_pred = dp.rename_df_columns({'predicted_mean': 'y'}, data=y_pred)\n",
    "                # Calculate the metric\n",
    "                if train_metric == 'aic':\n",
    "                    train_metric_val = sarimax_model_fit.aic\n",
    "                elif train_metric == 'mse':\n",
    "                    train_metric_val = mean_squared_error(test, y_pred)\n",
    "                elif train_metric == 'rmse':\n",
    "                    train_metric_val = np.sqrtr(mean_squared_error(test, y_pred))\n",
    "                \n",
    "                cv_metrics.append(train_metric_val)\n",
    "            # Aggregate the metrics\n",
    "            cv_metrics_agg = np.mean(cv_metrics)\n",
    "            # Update the best model\n",
    "            if cv_metrics_agg < self.best_metric_value:\n",
    "                self.best_metric_value = cv_metrics_agg\n",
    "                self.best_cv_params = params\n",
    "                self.best_cv_model = sarimax_model\n",
    "        print(f\"Training completed!\")\n",
    "        print(f\"Best parameters: {self.best_cv_params} obtained CV error of {self.best_metric_value:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grids\n",
    "p_values = range(0, 3)\n",
    "d_values = range(0, 2)\n",
    "q_values = range(0, 3)\n",
    "P_values = range(0, 3)\n",
    "D_values = range(0, 2)\n",
    "Q_values = range(0, 3)\n",
    "s_values = [12]\n",
    "\n",
    "param_grid = list(itertools.product(p_values, d_values, q_values, P_values, D_values, Q_values, s_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 2],\n",
       "       [0, 0, 2],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [0, 1, 2],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 0, 2],\n",
       "       [1, 0, 2],\n",
       "       [1, 0, 2],\n",
       "       [1, 0, 2],\n",
       "       [1, 0, 2],\n",
       "       [1, 0, 2],\n",
       "       [1, 0, 2],\n",
       "       [1, 0, 2],\n",
       "       [1, 0, 2],\n",
       "       [1, 0, 2],\n",
       "       [1, 0, 2],\n",
       "       [1, 0, 2],\n",
       "       [1, 0, 2],\n",
       "       [1, 0, 2],\n",
       "       [1, 0, 2],\n",
       "       [1, 0, 2],\n",
       "       [1, 0, 2],\n",
       "       [1, 0, 2],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 2],\n",
       "       [1, 1, 2],\n",
       "       [1, 1, 2],\n",
       "       [1, 1, 2],\n",
       "       [1, 1, 2],\n",
       "       [1, 1, 2],\n",
       "       [1, 1, 2],\n",
       "       [1, 1, 2],\n",
       "       [1, 1, 2],\n",
       "       [1, 1, 2],\n",
       "       [1, 1, 2],\n",
       "       [1, 1, 2],\n",
       "       [1, 1, 2],\n",
       "       [1, 1, 2],\n",
       "       [1, 1, 2],\n",
       "       [1, 1, 2],\n",
       "       [1, 1, 2],\n",
       "       [1, 1, 2],\n",
       "       [2, 0, 0],\n",
       "       [2, 0, 0],\n",
       "       [2, 0, 0],\n",
       "       [2, 0, 0],\n",
       "       [2, 0, 0],\n",
       "       [2, 0, 0],\n",
       "       [2, 0, 0],\n",
       "       [2, 0, 0],\n",
       "       [2, 0, 0],\n",
       "       [2, 0, 0],\n",
       "       [2, 0, 0],\n",
       "       [2, 0, 0],\n",
       "       [2, 0, 0],\n",
       "       [2, 0, 0],\n",
       "       [2, 0, 0],\n",
       "       [2, 0, 0],\n",
       "       [2, 0, 0],\n",
       "       [2, 0, 0],\n",
       "       [2, 0, 1],\n",
       "       [2, 0, 1],\n",
       "       [2, 0, 1],\n",
       "       [2, 0, 1],\n",
       "       [2, 0, 1],\n",
       "       [2, 0, 1],\n",
       "       [2, 0, 1],\n",
       "       [2, 0, 1],\n",
       "       [2, 0, 1],\n",
       "       [2, 0, 1],\n",
       "       [2, 0, 1],\n",
       "       [2, 0, 1],\n",
       "       [2, 0, 1],\n",
       "       [2, 0, 1],\n",
       "       [2, 0, 1],\n",
       "       [2, 0, 1],\n",
       "       [2, 0, 1],\n",
       "       [2, 0, 1],\n",
       "       [2, 0, 2],\n",
       "       [2, 0, 2],\n",
       "       [2, 0, 2],\n",
       "       [2, 0, 2],\n",
       "       [2, 0, 2],\n",
       "       [2, 0, 2],\n",
       "       [2, 0, 2],\n",
       "       [2, 0, 2],\n",
       "       [2, 0, 2],\n",
       "       [2, 0, 2],\n",
       "       [2, 0, 2],\n",
       "       [2, 0, 2],\n",
       "       [2, 0, 2],\n",
       "       [2, 0, 2],\n",
       "       [2, 0, 2],\n",
       "       [2, 0, 2],\n",
       "       [2, 0, 2],\n",
       "       [2, 0, 2],\n",
       "       [2, 1, 0],\n",
       "       [2, 1, 0],\n",
       "       [2, 1, 0],\n",
       "       [2, 1, 0],\n",
       "       [2, 1, 0],\n",
       "       [2, 1, 0],\n",
       "       [2, 1, 0],\n",
       "       [2, 1, 0],\n",
       "       [2, 1, 0],\n",
       "       [2, 1, 0],\n",
       "       [2, 1, 0],\n",
       "       [2, 1, 0],\n",
       "       [2, 1, 0],\n",
       "       [2, 1, 0],\n",
       "       [2, 1, 0],\n",
       "       [2, 1, 0],\n",
       "       [2, 1, 0],\n",
       "       [2, 1, 0],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 1],\n",
       "       [2, 1, 2],\n",
       "       [2, 1, 2],\n",
       "       [2, 1, 2],\n",
       "       [2, 1, 2],\n",
       "       [2, 1, 2],\n",
       "       [2, 1, 2],\n",
       "       [2, 1, 2],\n",
       "       [2, 1, 2],\n",
       "       [2, 1, 2],\n",
       "       [2, 1, 2],\n",
       "       [2, 1, 2],\n",
       "       [2, 1, 2],\n",
       "       [2, 1, 2],\n",
       "       [2, 1, 2],\n",
       "       [2, 1, 2],\n",
       "       [2, 1, 2],\n",
       "       [2, 1, 2],\n",
       "       [2, 1, 2]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(itertools.product(p_values, d_values, q_values, P_values, D_values, Q_values, s_values)))[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_cv = SarimaxGridSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 0, 0, 0, 0, 12)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[param_grid[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f8c16b64214511aad6da48e30d47ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed!\n",
      "Best parameters: (0, 0, 0, 0, 0, 0, 12) obtained CV error of 118686.84\n"
     ]
    }
   ],
   "source": [
    "sarima_cv = SarimaxGridSearchCV()\n",
    "sarima_cv.fit(co2_df, [param_grid[0]], train_metric='mse', tscv_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0, 0, 0, 0, 12)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_ts_split(data, train_size=0.8, split_date=None):\n",
    "    data = data.sort_index()\n",
    "    data_dates = data.index.unique()\n",
    "    \n",
    "    if split_date is None:\n",
    "        split_date = data_dates[int(len(data_dates) * train_size)]\n",
    "    split_date = pd.to_datetime(split_date)\n",
    "    \n",
    "    train = data.loc[data.index < split_date_dt]\n",
    "    test = data.loc[data.index >= split_date_dt]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_pdq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AEMW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader()\n",
    "df = dl.load_data('AEP_hourly.csv')\n",
    "dp = DataProcessor()\n",
    "dp = DataProcessor(df)\n",
    "dp.set_dt_index('Datetime', inplace=True)\n",
    "dp.rename_dt_index('dt', inplace=True)\n",
    "dp.rename_df_columns({'AEP_MW': 'y'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Superstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader()\n",
    "df = dl.load_data('superstore_data.csv')\n",
    "dp = DataProcessor()\n",
    "dp = DataProcessor(df)\n",
    "dp.set_dt_index('Order Date', inplace=True)\n",
    "dp.rename_dt_index('dt', inplace=True)\n",
    "dp.select_columns(['Sales'], inplace=True)\n",
    "dp.rename_df_columns(col_name_map={'Sales': 'y'}, inplace=True)\n",
    "df = dp.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
